# -*- coding: utf-8 -*-
"""Курсовая работа_Прогноз цен на недвижимость.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aS2DqHIFwOakRbGPTTX6HypVIsK03AD3

# ***Прогноз цен на недвижимость***

Описания файлов
train.csv — обучающий набор
test.csv - тестовый набор
sampleSubmission.csv — образец файла отправки в правильном формате.
Поля данных
Id - объемный номер квартиры
DistrictId - распространенный номер района
Комнаты - количество комнат
Площадь - площадь
LifeSquare - жилая площадь
KitchenSquare - площадь кухни
Этаж - этаж
HouseFloor - количество этажей в доме
HouseYear - год постройки дома
Экология_1, Экология_2, Экология_3 - экологические оценки местности
Social_1, Social_2, Social_3 - социальные области местности
Здравоохранение_1, Здравоохранение_2 - границы местности, связанные с охраной здоровья
Shops_1, Shops_2 - показатели, связанные с наличием магазинов, торговых центров
Цена - цена квартиры

**Подключение библиотек и скриптов**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import random

import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from datetime import datetime

from scipy.stats import mode

import warnings
warnings.filterwarnings('ignore')

matplotlib.rcParams.update({'font.size': 14})

from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score as r2
from sklearn.model_selection import KFold, GridSearchCV
from sklearn.manifold import TSNE

"""**Добавляем функцию для расчета метрик на данных и построении графиков**"""

def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):
    print("Train R2:\t" + str(round(r2(train_true_values, train_pred_values), 3)))
    print("Test R2:\t" + str(round(r2(test_true_values, test_pred_values), 3)))
    
    plt.figure(figsize=(18,10))
    
    plt.subplot(121)
    sns.scatterplot(x=train_pred_values, y=train_true_values)
    plt.xlabel('Predicted values')
    plt.ylabel('True values')
    plt.title('Train sample prediction')
    
    plt.subplot(122)
    sns.scatterplot(x=test_pred_values, y=test_true_values)
    plt.xlabel('Predicted values')
    plt.ylabel('True values')
    plt.title('Test sample prediction')

    plt.show()

"""**Пути к директориям и файлам**"""

TRAIN_DATASET_PATH = './train.csv'
TEST_DATASET_PATH = './test.csv'

"""**1. Загрузка данных**

**Описание задачи**

Цель - предсказать цены на квартиры

**Описание датасета**

* **Id** - идентификационный номер квартиры
* **DistrictId** - идентификационный номер района
* **Rooms** - количество комнат
* **Square** - площадь
* **LifeSquare** - жилая площадь
* **KitchenSquare** - площадь кухни
* **Floor** - этаж
* **HouseFloor** - количество этажей в доме
* **HouseYear** - год постройки дома
* **Ecology_1, Ecology_2, Ecology_3** - экологические показатели местности
* **Social_1, Social_2, Social_3** - социальные показатели местности
* **Healthcare_1, Helthcare_2** - показатели местности, связанные с охраной здоровья
* **Shops_1, Shops_2** - показатели, связанные с наличием магазинов, торговых центров
* **Price** - цена квартиры

Считываем данные. По строкам - наблюдения, по столбцам - признаки.

Train данные
"""

train_df = pd.read_csv(TRAIN_DATASET_PATH)
train_df.head(5)

train_df.columns

"""Test данные"""

test_df = pd.read_csv(TEST_DATASET_PATH)
test_df.head(5)

print('Строк в train:', train_df.shape)
print('Строк в test', test_df.shape)

"""Зависимость признаков"""

plt.figure(figsize = (20,15))

sns.set(font_scale=1.4)

corr_matrix = train_df.corr()
corr_matrix = np.round(corr_matrix, 2)

sns.heatmap(corr_matrix, annot=True, linewidths=1, cmap='coolwarm')

plt.title('Матрица корреляции')
plt.show()

"""На основании матрицы корреляции можно увидеть зависимость стоимости квартиры от количества комнат и общей площади.

Высокая корреляция (0.96) между Social_1 и Social_2_эти два показателя можно объединить.

**2. Приведение типовых данных**
"""

train_df.dtypes

train_df.dtypes.value_counts()

"""Категориальные данные ID и Districtld изменим на строковые параметры, чтобы исключить их из обучения:"""

train_df['Id'] = train_df['Id'].astype(str)
train_df['DistrictId'] = train_df['DistrictId'].astype(str)
train_df.dtypes

train_df.dtypes.value_counts()

"""**3. Обзор данных и обработка данных**

**Целевая переменная**
"""

plt.figure(figsize= (12,8))

train_df['Price'].hist (bins=50)
plt.ylabel ('Count')
plt.xlabel ('Price')

plt.title('Распределение цены')
plt.show()

target_mean = round(train_df['Price'].mean(), 2)
target_median = round(train_df['Price'].median(),2)

target_mean, target_median

plt.figure(figsize = (12, 8))

sns.distplot(train_df['Price'], bins = 50)

y = np.linspace(0, 0.000005, 2) #(2 точки для рисования прямой линии на графике)
plt.plot([target_mean] * 2, y, label = 'mean', linewidth = 4)
plt.plot([target_median] * 2, y, label = 'median', linewidth = 4)

plt.suptitle('Распределение цены')
plt.legend()
plt.show()

"""**Количественные переменные**

Первичное понимание, что представляют собой данные
"""

train_df.describe()

print('Количество нулевых значений =', str(train_df.isnull().sum().sum()))

train_df.isna().sum()

train_df.select_dtypes(include=['float64', 'int64', 'float16']).hist(figsize=(26,26), bins=20, grid=False);

"""**Номинативные переменные**"""

train_df.select_dtypes(include='object').columns.tolist()

train_df['DistrictId'].value_counts()

train_df['Ecology_2'].value_counts()

train_df['Ecology_3'].value_counts()

train_df['Shops_2'].value_counts()

"""**4. Обработка пропусков и выбросов**

**ROOMS**
"""

train_df_num_features = train_df.select_dtypes(include=['float64', 'int64'])
train_df_num_features.head()

train_df['Rooms'].value_counts()

"""Добавляем новый бинарный признак для помечания выбросов по комнатам.
Заменим нулевые значения на медиану, а там где 5 и более комнат оставим 5-комнатные квартиры.
"""

train_df['Rooms_outlier'] = 0
train_df.loc[(train_df['Rooms'] == 0) | (train_df['Rooms'] >= 6), 'Rooms_outlier'] = 1
train_df.head()

target_mean = round(train_df['Rooms'].mean(), 2)
target_median = round(train_df['Rooms'].median(),2)

target_mean, target_median

train_df.loc[train_df['Rooms'] == 0, 'Rooms'] = train_df['Rooms'].median()
train_df.loc[train_df['Rooms'] >= 5, 'Rooms'] = 5

train_df['Rooms'].value_counts()

"""**Square, LifeSquare, KitchenSquare**"""

train_df.describe()

"""В столбцах Square, LifeSquare, KitchenSquare -  есть как странные большие площади, так и нулевые и очень маленькие показатели. В LifeSquare - заполнены только 7887 из 10000 значений, и где общая площадь меньше жилой.

Посмотрим через квантили
"""

train_df['Square'].quantile(.99), train_df['Square'].quantile(.01)

target_mean = round(train_df['Square'].mean(), 2)
target_median = round(train_df['Square'].median(),2)

target_mean, target_median

train_df['LifeSquare'].quantile(.975), train_df['LifeSquare'].quantile(.025)

target_mean = round(train_df['LifeSquare'].mean(), 2)
target_median = round(train_df['LifeSquare'].median(),2)

target_mean, target_median

train_df['KitchenSquare'].value_counts()

train_df['KitchenSquare'].quantile(.975), train_df['KitchenSquare'].quantile(.025)

target_mean = round(train_df['KitchenSquare'].mean(), 2)
target_median = round(train_df['KitchenSquare'].median(),2)

target_mean, target_median

"""Предположим, что нулевые значения по кухне указаны в квартирах - студиях, чтобы не увеличивать площадь и исключить нулевые значения - заменим их на 1.

большие площади = выбросы - заменим на значение медианы
"""

condition = (train_df['KitchenSquare'].isna()) \
             | (train_df['KitchenSquare'] > train_df['KitchenSquare'].quantile(.975))
        
train_df.loc[condition, 'KitchenSquare'] = train_df['KitchenSquare'].median()

train_df.loc[train_df['KitchenSquare'] < 1, 'KitchenSquare'] = 1

train_df['KitchenSquare'].value_counts()

condition = (train_df['Square'].isna()) \
             | (train_df['Square'] > train_df['Square'].quantile(.99))
        
train_df.loc[condition, 'Square'] = train_df['Square'].median()

condition = (train_df['Square'].isna()) \
             | (train_df['Square'] < train_df['Square'].quantile(.01))
        
train_df.loc[condition, 'Square'] = train_df['Square'].median()

"""проверяем, где  Общая площадь меньше суммарной площади кухни, жилой и нежилой (условно взять 3 кв.м)"""

((train_df['KitchenSquare']+train_df['LifeSquare']+3) > train_df['Square']).sum()

condition = (train_df['LifeSquare'].isna()) \
             | (train_df['LifeSquare'] < train_df['LifeSquare'].quantile(.01))
        
train_df.loc[condition, 'LifeSquare'] = train_df['LifeSquare'].median()

train_df.loc[(train_df['LifeSquare'] > train_df['Square'] - train_df['KitchenSquare'] - 3),'LifeSquare'] = train_df['Square'] - train_df['KitchenSquare'] - 3

((train_df['KitchenSquare']+train_df['LifeSquare']+3) > train_df['Square']).sum()

train_df.describe()

"""**HouseFloor, Floor**

В значениях этажей - есть значения, кторые не вписываются в этажность дома.

Добавляем новый признак, где этажность равна 0, либо этаж выше этажности.
Нулевые этажности заменяем на медиану
Если этаж выше этажности = меняем местами
"""

(train_df['Floor'] > train_df['HouseFloor']).sum()

train_df['HouseFloor_outlier'] = 0
train_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1
train_df.loc[train_df['Floor'] > train_df['HouseFloor'], 'HouseFloor_outlier'] = 1

train_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor'] = train_df['HouseFloor'].median()

train_df.loc[(train_df['HouseFloor'] < train_df['Floor']), 'HouseFloor'] = train_df.loc[(train_df['HouseFloor'] < train_df['Floor']), 'Floor']

(train_df['Floor'] > train_df['HouseFloor']).sum()

"""**HouseYear**"""

train_df['HouseYear'].sort_values(ascending=False)

"""год подстройки 20052011 - это 2005 2011.
Заменим данный показатель на 2011
Год 4968 = 1968
"""

train_df.loc[train_df['HouseYear']  == 4968, 'HouseYear'] = 1968
train_df.loc[train_df['HouseYear']  == 20052011, 'HouseYear'] = 2011

train_df['HouseYear'].sort_values(ascending=False)

train_df.isna().sum()

"""48% Healthcear_1 - не заполнены (4798 из 10000), и так как выше мы смотрели по матрице корреляций - не было зависимости по данному показателю, то можно не учитывать в модели"""

train_df['Healthcare_1'].head()

train_df.drop('Healthcare_1', axis=1, inplace=True)

train_df.isna().sum()

"""**Класс обработки данных**"""

class DataPreprocessing:
    """Подготовка исходных данных"""

    def __init__(self):
        """Параметры класса"""
        self.medians = None
        self.kitchen_square_quantile = None
        self.life_square_quantile = None
        self.square_quantile = None
        self.square_quantile2 = None

    def fit(self, X):
        """Сохранение статистик"""       
        # Расчет медиан
        self.medians = X.median()
        self.kitchen_square_quantile = X['KitchenSquare'].quantile(.975)
        self.life_square_quantile = X['LifeSquare'].quantile(.01)
        self.square_quantile = X['Square'].quantile(.99)
        self.square_quantile2 = X['Square'].quantile(.01)

    def transform(self, X):
        """Трансформация данных"""

        # Rooms
        X['Rooms_outlier'] = 0
        X.loc[(X['Rooms'] == 0) | (X['Rooms'] >= 6), 'Rooms_outlier'] = 1
        
        X.loc[X['Rooms'] == 0, 'Rooms'] = self.medians['Rooms']
        X.loc[X['Rooms'] >= 5, 'Rooms'] = 5

         # Square, KitchenSquare, LifeSquare
        condition = (X['KitchenSquare'].isna()) | (X['KitchenSquare'] > self.kitchen_square_quantile)
        X.loc[condition, 'KitchenSquare'] = self.medians['KitchenSquare']
        X.loc[X['KitchenSquare'] < 1, 'KitchenSquare'] = 1
        
        condition = (X['LifeSquare'].isna()) | (X['LifeSquare'] < self.life_square_quantile)
        X.loc[condition, 'LifeSquare'] = self.medians['LifeSquare']
        X.loc[condition, 'LifeSquare'] = X.loc[condition, 'Square'] - X.loc[condition, 'KitchenSquare'] - 3

        condition = (X['Square'].isna()) | (X['Square'] > self.square_quantile)
        X.loc[condition, 'Square'] = self.medians['Square']
        condition = (X['Square'].isna()) | (X['Square'] < self.square_quantile2)
        X.loc[condition, 'Square'] = self.medians['Square']

        
        # HouseFloor, Floor
        X['HouseFloor_outlier'] = 0
        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1
        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1
        
        X.loc[X['HouseFloor'] == 0, 'HouseFloor'] = self.medians['HouseFloor']
        X.loc[X['HouseFloor'] < X['Floor'], 'HouseFloor'] = X.loc[X['HouseFloor'] < X['Floor'], 'Floor']                                           
        
        # HouseYear
        current_year = datetime.now().year
        
        X['HouseYear_outlier'] = 0
        
        def HouseYear_cat(X):

            X.loc[X['HouseYear'] == 4968, 'HouseYear'] = 1968
            X.loc[X['HouseYear'] == 20052011, 'HouseYear'] = 2011

            return X

        X = HouseYear_cat(X)

        # Healthcare_1
        if 'Healthcare_1' in X.columns:
            X.drop('Healthcare_1', axis=1, inplace=True)
               
        
        
        X.fillna(self.medians, inplace=True)
        
        return X

"""**Новые признаки**

Переведем категориальные признаки в бинарные (экология_1, экология_2, магазины_2)
"""

binary_to_numbers = {'A': 0, 'B': 1}

train_df['Ecology_2'] = train_df['Ecology_2'].replace(binary_to_numbers)
train_df['Ecology_3'] = train_df['Ecology_3'].replace(binary_to_numbers)
train_df['Shops_2'] = train_df['Shops_2'].replace(binary_to_numbers)

"""Добавим на основе районов - признак частоты"""

district_size = train_df['DistrictId'].value_counts().reset_index()\
                    .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})

district_size.head()

train_df = train_df.merge(district_size, on='DistrictId', how='left')
train_df.head()

(train_df['DistrictSize'] > 100).value_counts()

train_df['IsDistrictLarge'] = (train_df['DistrictSize'] > 100).astype(int)

"""Закодируем целевой признак через район и количество комнат"""

med_price_by_district = train_df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\
                            .rename(columns={'Price':'MedPriceByDistrict'})

med_price_by_district.head()

med_price_by_district.shape

train_df = train_df.merge(med_price_by_district, on=['DistrictId', 'Rooms'], how='left')
train_df.head()

"""Закодируем целевой признак через этаж и год MedPriceByFloorYear"""

def floor_to_cat(X):

    X['floor_cat'] = 0

    X.loc[X['Floor'] <= 2, 'floor_cat'] = 1  
    X.loc[(X['Floor'] > 2) & (X['Floor'] <= 5), 'floor_cat'] = 2
    X.loc[(X['Floor'] > 5) & (X['Floor'] <= 9), 'floor_cat'] = 3
    X.loc[(X['Floor'] > 9) & (X['Floor'] <= 15), 'floor_cat'] = 4
    X.loc[X['Floor'] > 15, 'floor_cat'] = 5

    return X

def floor_to_cat_pandas(X):
    bins = [X['Floor'].min(), 2, 5, 9, 15, X['Floor'].max()]
    X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)
    
    X['floor_cat'].fillna(-1, inplace=True)
    return X

def year_to_cat(X):

    X['year_cat'] = 0

    X.loc[X['HouseYear'] <= 1932, 'year_cat'] = 1
    X.loc[(X['HouseYear'] > 1932) & (X['HouseYear'] <= 1961), 'year_cat'] = 2
    X.loc[(X['HouseYear'] > 1961) & (X['HouseYear'] <= 1980), 'year_cat'] = 3
    X.loc[(X['HouseYear'] > 1980) & (X['HouseYear'] <= 2000), 'year_cat'] = 4
    X.loc[(X['HouseYear'] > 2000) & (X['HouseYear'] <= 2010), 'year_cat'] = 5
    X.loc[(X['HouseYear'] > 2010), 'year_cat'] = 6

    return X

def year_to_cat_pandas(X):
    bins = [X['HouseYear'].min(), 1932, 1961, 1980, 2000, 2010, X['HouseYear'].max()]
    X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)
    
    X['year_cat'].fillna(-1, inplace=True)
    return X

bins = [train_df['Floor'].min(), 2, 5, 9, 15, train_df['Floor'].max()]
pd.cut(train_df['Floor'], bins=bins, labels=False)

bins = [train_df['Floor'].min(), 2, 5, 9, 15, train_df['Floor'].max()]
pd.cut(train_df['Floor'], bins=bins)

train_df = year_to_cat(train_df)
train_df = floor_to_cat(train_df)
train_df.head()

"""Группируем по году и этажу"""

med_price_by_floor_year = train_df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\
                                            rename(columns={'Price':'MedPriceByFloorYear'})
med_price_by_floor_year.head()

train_df = train_df.merge(med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')
train_df.head()

"""**Класс обработки данных_новые признаки**"""

class FeatureGenetator():
    """Генерация новых фич"""
    
    def __init__(self):
        self.DistrictId_counts = None
        self.binary_to_numbers = None
        self.district_size = None
        self.med_price_by_district = None
        self.med_price_by_floor_year = None
        self.floor_max = None
        self.floor_min = None
        self.house_year_max = None
        self.house_year_min = None
        
         
    def fit(self, X, y=None):
        
        X = X.copy()
        
        # Binary features
        self.binary_to_numbers = {'A': 0, 'B': 1}
        
        # DistrictID
        self.district_size = X['DistrictId'].value_counts().reset_index() \
                               .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})
        # Target encoding
        ## District, Rooms
        df = X.copy()
        
        if y is not None:
            df['Price'] = y.values
            
            self.med_price_by_district = df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\
                                            .rename(columns={'Price':'MedPriceByDistrict'})
            self.med_price_by_district_median = self.med_price_by_district['MedPriceByDistrict'].median()
        
         ## floor, year
        if y is not None:
            self.floor_max = df['Floor'].max()
            self.floor_min = df['Floor'].min()
            self.house_year_max = df['HouseYear'].max()
            self.house_year_min = df['HouseYear'].min()
            df['Price'] = y.values
            df = self.floor_to_cat(df)
            df = self.year_to_cat(df)
            self.med_price_by_floor_year = df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\
                                            rename(columns={'Price':'MedPriceByFloorYear'})
            self.med_price_by_floor_year_median = self.med_price_by_floor_year['MedPriceByFloorYear'].median()
        


       
    def transform(self, X):
        
        # Binary features
        X['Ecology_2'] = X['Ecology_2'].map(self.binary_to_numbers)  # self.binary_to_numbers = {'A': 0, 'B': 1}
        X['Ecology_3'] = X['Ecology_3'].map(self.binary_to_numbers)
        X['Shops_2'] = X['Shops_2'].map(self.binary_to_numbers)
        
        # DistrictId, IsDistrictLarge
        X = X.merge(self.district_size, on='DistrictId', how='left')
        
        X['new_district'] = 0
        X.loc[X['DistrictSize'].isna(), 'new_district'] = 1
        
        X['DistrictSize'].fillna(5, inplace=True)
        
        X['IsDistrictLarge'] = (X['DistrictSize'] > 100).astype(int)
        
        
        # More categorical features
        X = self.floor_to_cat(X)  
        X = self.year_to_cat(X)   

         
        # Target encoding
        if self.med_price_by_district is not None:
            X = X.merge(self.med_price_by_district, on=['DistrictId', 'Rooms'], how='left')
            X['MedPriceByDistrict'].fillna(self.med_price_by_district_median, inplace=True)
            
        if self.med_price_by_floor_year is not None:
            X = X.merge(self.med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')
            X['MedPriceByFloorYear'].fillna(self.med_price_by_floor_year_median, inplace=True)
        
        return X

    def floor_to_cat(self, X):
        bins = [self.floor_min, 3, 5, 9, 15, self.floor_max]
        X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)

        X['floor_cat'].fillna(-1, inplace=True)
        return X
     
    def year_to_cat(self, X):
        bins = [self.house_year_min, 1950, 1980, 2000, 2015, self.house_year_max]
        X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)

        X['year_cat'].fillna(-1, inplace=True)
        return X

"""**Отбор признаков**"""

train_df.columns.tolist()

feature_names = ['Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',
                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3',
                 'Helthcare_2', 'Shops_1', 'Shops_2']

new_feature_names = ['Rooms_outlier', 'HouseFloor_outlier', 'HouseYear_outlier', 'LifeSquare_nan', 'DistrictSize',
                     'new_district', 'IsDistrictLarge', 'MedPriceByFloorYear']

target_name = 'Price'

"""**5. Разбиение на Train и Test**"""

train_df = pd.read_csv(TRAIN_DATASET_PATH)
test_df = pd.read_csv(TEST_DATASET_PATH)

X = train_df.drop(columns=target_name)
y = train_df[target_name]

X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=42)

preprocessor = DataPreprocessing()
preprocessor.fit(X_train)

X_train = preprocessor.transform(X_train)
X_valid = preprocessor.transform(X_valid)
test_df = preprocessor.transform(test_df)

X_train.shape, X_valid.shape, test_df.shape

features_gen = FeatureGenetator()
features_gen.fit(X_train, y_train)

X_train = features_gen.transform(X_train)
X_valid = features_gen.transform(X_valid)
test_df = features_gen.transform(test_df)

X_train.shape, X_valid.shape, test_df.shape

X_train.isna().sum().sum(), X_valid.isna().sum().sum(), test_df.isna().sum().sum()

"""**6. Построение модели**

Линейная регрессия
"""

#from sklearn.linear_model import LinearRegression
#lr_model = LinearRegression()

#lr_model.fit(X_train, y_train)
             
#y_train_preds = lr_model.predict(X_train)
#y_test_preds = lr_model.predict(X_valid)

#evaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)

"""RandomForestRegressor"""

#%%time
#from sklearn.ensemble import RandomForestRegressor
#rf_model = RandomForestRegressor(n_estimators=1000, max_depth=10, random_state=42)
#rf_model.fit(X_train, y_train)

#y_train_preds = rf_model.predict(X_train)
#y_test_preds = rf_model.predict(X_valid)

#evaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)

"""Кросс-валидация"""

#from numpy.core.numeric import cross
#from sklearn.model_selection import cross_val_score
#cv_score = cross_val_score(rf_model, X_train, y_train, scoring='r2', cv=KFold(n_splits=3, shuffle=True, random_state=21))
#cv_score

#cv_score.mean()

"""Важность признаков"""

#feature_importances = pd.DataFrame(zip(X_train.columns, rf_model.feature_importances_), 
                                   #columns=['feature_name', 'importance'])

#feature_importances.sort_values(by='importance', ascending=False).head(10)

"""LigthGBMRegressor"""

import lightgbm as lgb

gbm = lgb.LGBMRegressor(max_depth=15, n_estimators=200)
gbm.fit(X_train, y_train)

y_train_preds = gbm.predict(X_train)
y_test_preds = gbm.predict(X_valid)

evaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)

cv_score = cross_val_score(gbm, X_train, y_train, scoring='r2', cv=KFold(n_splits=3, shuffle=True, random_state=21))
cv_score

cv_score.mean()

feature_importances = pd.DataFrame(zip(X_train.columns, gbm.feature_importances_), 
                                   columns=['feature_name', 'importance'])

feature_importances.sort_values(by='importance', ascending=False).head(10)

"""XGBoost"""

#from xgboost import XGBRegressor

#xgbr = XGBRegressor(random_state=42,n_estimators=500,max_depth=3)
#xgbr.fit(X_train, y_train)

#y_train_preds = xgbr.predict(X_train)
#y_test_preds = xgbr.predict(X_valid)

#evaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)

#cv_score = cross_val_score(xgbr, X_train, y_train, scoring='r2', cv=KFold(n_splits=3, shuffle=True, random_state=21))
#cv_score

#cv_score.mean()

"""**7.ПРОГНОЗ по тестовым данным**

**Линейная регрессия**

Train R2: 0.718/
Test R2: 0.523

**RandomForestRegressor**

Train R2:	0.894/
Test R2:	0.649

**LigthGBMRegressor**

Train R2: 0.932/
Test R2: 0.68

**XGBoost**

Train R2: 0.871/
Test R2: 0.677

обучения тестовых получились невысокие, кросс-валидация наибольшая у XGBoost, но практически на LigthGBMRegressor.


Поэтому оставнавлюсь на модели **LigthGBMRegressor**. Остальные оставлю в комментариях
"""

test_df.shape

test_df

submit = pd.read_csv('./sample_submission.csv')
submit.head(10)

predictions = gbm.predict(test_df)
predictions

submit['Price'] = predictions
submit.head()

submit.to_csv('gbm_submit.csv', index=False)